{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iRNrPqWWI4EC"
      },
      "outputs": [],
      "source": [
        "!pip install konlpy"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U pyLDAvis"
      ],
      "metadata": {
        "id": "awArNiBWJONl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd"
      ],
      "metadata": {
        "id": "IeBC5U5_JivD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('다이소_유튜브_제목.csv')\n",
        "df.columns = ['0', '제목']\n",
        "df.head()"
      ],
      "metadata": {
        "id": "JDC_F1KEJnLz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.drop(\"0\",axis=1,inplace=True)"
      ],
      "metadata": {
        "id": "EzLUQM3_RTEn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "id": "vxU2bkIGRXMO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from konlpy.tag import Okt\n",
        "import re"
      ],
      "metadata": {
        "id": "qDPD-KMPJ5Wr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenize_text(text):\n",
        "    text = re.sub(r\"[^ㄱ-ㅣ가-힣\\s]\",\"\",text)\n",
        "    okt = Okt()\n",
        "    okt_morphs = okt.pos(text)\n",
        "\n",
        "    words = []\n",
        "    for word,pos in okt_morphs: \n",
        "        if pos == 'Adjective' or pos=='Verb' or pos=='Noun':\n",
        "            words.append(word)\n",
        "\n",
        "    word_str =  ' '.join(words)  \n",
        "    return word_str"
      ],
      "metadata": {
        "id": "NdN77HhbLP2i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "token_list = []\n",
        "for temp in tqdm(df['제목']):\n",
        "    token_list.append(tokenize_text(temp))\n",
        "token_list"
      ],
      "metadata": {
        "id": "gyrL-xmQM9YL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "drop_corpus = []\n",
        "\n",
        "for index in range(len(token_list)):\n",
        "    corpus = token_list[index]\n",
        "    if len(set(corpus.split())) < 3:\n",
        "        drop_corpus.append(corpus)\n",
        "\n",
        "for corpus in drop_corpus:\n",
        "    token_list.remove(corpus)\n",
        "\n",
        "token_list"
      ],
      "metadata": {
        "id": "HL-F-cEQND2S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.decomposition import LatentDirichletAllocation"
      ],
      "metadata": {
        "id": "6yiLKFfrRRNK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "count_vec = CountVectorizer(max_df=0.2,max_features=1000,min_df=3,ngram_range=(1,2))\n",
        "feat_vect = count_vec.fit_transform(token_list)\n",
        "print(feat_vect.shape)\n",
        "print(count_vec.vocabulary_)"
      ],
      "metadata": {
        "id": "VUsO2gwPU9sD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "feature_names = count_vec.get_feature_names_out()"
      ],
      "metadata": {
        "id": "nY3Dje-kXpd_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lda = LatentDirichletAllocation(n_components=5,max_iter=20)\n",
        "lda.fit(feat_vect)"
      ],
      "metadata": {
        "id": "gSc919FwV2F7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lda.components_"
      ],
      "metadata": {
        "id": "na2jda2XYKeX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def display_topics(model,feature_names,num_top_words):\n",
        "    for topic_index, topic in enumerate(model.components_):\n",
        "        print('토픽',topic_index)\n",
        "        topic_word_indexes = topic.argsort()[::-1]\n",
        "        top_index = topic_word_indexes[:num_top_words]\n",
        "       \n",
        "        f_name_list = []\n",
        "        for temp in top_index:\n",
        "            f_name_list.append(feature_names[temp])\n",
        "\n",
        "        feature_concat = ' '.join(f_name_list)\n",
        "        print(feature_concat)\n",
        "    "
      ],
      "metadata": {
        "id": "iVdt3Q2MWgdh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "display_topics(lda,feature_names,15)"
      ],
      "metadata": {
        "id": "2aN2vIKUZFDX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pyLDAvis.lda_model\n",
        "pyLDAvis.enable_notebook()\n",
        "vis = pyLDAvis.lda_model.prepare(lda,feat_vect,count_vec)\n",
        "pyLDAvis.display(vis)"
      ],
      "metadata": {
        "id": "pmp-HCUgZKLm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sent_topic = lda.transform(feat_vect)\n",
        "print(sent_topic[0])"
      ],
      "metadata": {
        "id": "L9MbFvkOeHg0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "doc_per_topic_list = []\n",
        "for n in range(sent_topic.shape[0]):\n",
        "    topic_most_pr = sent_topic[n].argmax()\n",
        "    topic_pr = sent_topic[n].max()\n",
        "    doc_per_topic_list.append([n,topic_most_pr,topic_pr])\n",
        "\n",
        "doc_topic_df = pd.DataFrame(doc_per_topic_list,columns=['no','토픽번호','확률'])\n",
        "doc_topic_df\n",
        "\n"
      ],
      "metadata": {
        "id": "GTa1Jzt8hQAE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for topic in range(len(doc_topic_df['토픽번호'].unique())):\n",
        "    print('토픽',topic)\n",
        "    top_topic = doc_topic_df[ doc_topic_df['토픽번호']==topic].sort_values(by='확률',ascending=False)\n",
        "    print(df['제목'].iloc[ top_topic['no'].iloc[0]])\n",
        "    print(df['제목'].iloc[ top_topic['no'].iloc[1]])\n",
        "    print(df['제목'].iloc[ top_topic['no'].iloc[2]])"
      ],
      "metadata": {
        "id": "I8p6GKKIiKRk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 분석 결과"
      ],
      "metadata": {
        "id": "7G-AhkSoE4l7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1**  \n",
        "정리, 가지, 품절, 게시 살림, 출시, 구매, 주방, 즉시, 입고, 입고 즉시, 즉시 품절, 급상승, 매출, 다이소 꿀템, 살림 개월, 매출 급상승, 신상, 하세요, 다이소 신상, 꿀템 가지, 꿀팁, 베스트 셀러, 구매 하세요, 수납, 출시 매출, 다이소 출시, 만들기, 추천 가지, 추천 다이소\n",
        "\n",
        "**2**   \n",
        "하는, 리뷰, 후호, 가지, 게시 리뷰, 캠핑, 용품, 리뷰 하는, 가성, 하는 호랭, 호랭, 모르면, 모르면 후호, 베품, 호랭 개월, 가기, 후회 다이소, 사세요, 다이소 가기, 영상, 추천 게시, 추천 가지, 다이소 꿀템, 생활, 이건, 가면, 정리, 야할, 꿀템 게시, 캠핑 용품\n",
        "\n",
        "**3**    \n",
        "구매, 보이, 사세요, 가지, 하기, 게시 짤컷, 짤것, 짤것 개월, 다이소 꿀템, 게시 살림, 당장, 게시 개월, 쇼핑, 베스트, 가자 게시, 화장품, 셀러, 베스트 셀러, 다이소 보이, 직원, 품절, 가성, 무조건, 진짜, 하세요, 구매 하세요, 하기 게시, 고민, 무조건 사세요\n",
        "\n",
        "**4**     \n",
        "천원, 상품, 신상, 짜리, 리뷰, 게시 다이소, 다이소 상품, 다이소 신상, 게시 살림, 시간, 다이소 천원, 후회, 리뷰 게시, 하는, 다이소 다이소, 추천 게시, 다이소 꿀템, 인기, 추천 다이소, 주차, 주차 다이소, 출시, 사야, 뷰티, 남자, 로그, 지금, 일상, 하는 다이소, 다이소 개월\n",
        "\n",
        "**5**    \n",
        "다이소 꿀템, 꿀템 다이소, 추천 다이소, 다이소 다이소, 신상, 가지, 다이소 신상, 다이소 살림, 살림 다이소, 게시 살림, 직원, 몰래, 가지 다이소, 포장, 산다, 신상 다이소, 활용, 추천 가지, 이편, 이편 한살림, 한살림, 산다 다이소, 생활용품, 수납, 차박, 생활, 직원 몰래, 품절, 게시 개월\n"
      ],
      "metadata": {
        "id": "VhApngZNSFsG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **결론**"
      ],
      "metadata": {
        "id": "6cnwJ69JFQga"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "토픽 모두 공통적으로 '추천','꿀템','꿀팁','신상'등의 키워드를 볼 수 있었으며, 유튜브 다이소 영상의 대부분이이 다이소 물건을 추천하거나, 활용 방법등을 소개하는 내용임을을 알 수 있었다."
      ],
      "metadata": {
        "id": "LNhVlR6JUfNT"
      }
    }
  ]
}