{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iRNrPqWWI4EC"
      },
      "outputs": [],
      "source": [
        "!pip install konlpy"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U pyLDAvis"
      ],
      "metadata": {
        "id": "awArNiBWJONl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd"
      ],
      "metadata": {
        "id": "IeBC5U5_JivD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('샵다이소_구글앱_리뷰_정제.csv')\n",
        "df.head()"
      ],
      "metadata": {
        "id": "JDC_F1KEJnLz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from konlpy.tag import Okt\n",
        "import re"
      ],
      "metadata": {
        "id": "qDPD-KMPJ5Wr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenize_text(text):\n",
        "    text = re.sub(r\"[^ㄱ-ㅣ가-힣\\s]\",\"\",text)\n",
        "    okt = Okt()\n",
        "    okt_morphs = okt.pos(text)\n",
        "\n",
        "    words = []\n",
        "    for word,pos in okt_morphs: \n",
        "        if pos == 'Adjective' or pos=='Verb' or pos=='Noun':\n",
        "            words.append(word)\n",
        "\n",
        "    word_str =  ' '.join(words)  \n",
        "    return word_str"
      ],
      "metadata": {
        "id": "NdN77HhbLP2i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "token_list = []\n",
        "for temp in tqdm(df['text']):\n",
        "    token_list.append(tokenize_text(temp))\n",
        "token_list"
      ],
      "metadata": {
        "id": "gyrL-xmQM9YL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "drop_corpus = []\n",
        "\n",
        "for index in range(len(token_list)):\n",
        "    corpus = token_list[index]\n",
        "    if len(set(corpus.split())) < 3:\n",
        "        drop_corpus.append(corpus)\n",
        "\n",
        "for corpus in drop_corpus:\n",
        "    token_list.remove(corpus)\n",
        "\n",
        "token_list"
      ],
      "metadata": {
        "id": "HL-F-cEQND2S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.decomposition import LatentDirichletAllocation"
      ],
      "metadata": {
        "id": "6yiLKFfrRRNK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "count_vec = CountVectorizer(max_df=0.2,max_features=1000,min_df=3,ngram_range=(1,2))\n",
        "feat_vect = count_vec.fit_transform(token_list)\n",
        "print(feat_vect.shape)\n",
        "print(count_vec.vocabulary_)"
      ],
      "metadata": {
        "id": "VUsO2gwPU9sD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "feature_names = count_vec.get_feature_names_out()"
      ],
      "metadata": {
        "id": "nY3Dje-kXpd_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lda = LatentDirichletAllocation(n_components=5,max_iter=20)\n",
        "lda.fit(feat_vect)"
      ],
      "metadata": {
        "id": "gSc919FwV2F7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lda.components_"
      ],
      "metadata": {
        "id": "na2jda2XYKeX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def display_topics(model,feature_names,num_top_words):\n",
        "    for topic_index, topic in enumerate(model.components_):\n",
        "        print('토픽',topic_index)\n",
        "        topic_word_indexes = topic.argsort()[::-1]\n",
        "        top_index = topic_word_indexes[:num_top_words]\n",
        "       \n",
        "        f_name_list = []\n",
        "        for temp in top_index:\n",
        "            f_name_list.append(feature_names[temp])\n",
        "\n",
        "        feature_concat = ' '.join(f_name_list)\n",
        "        print(feature_concat)\n",
        "    "
      ],
      "metadata": {
        "id": "iVdt3Q2MWgdh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "display_topics(lda,feature_names,15)"
      ],
      "metadata": {
        "id": "2aN2vIKUZFDX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pyLDAvis.lda_model\n",
        "pyLDAvis.enable_notebook()\n",
        "vis = pyLDAvis.lda_model.prepare(lda,feat_vect,count_vec)\n",
        "pyLDAvis.display(vis)"
      ],
      "metadata": {
        "id": "pmp-HCUgZKLm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sent_topic = lda.transform(feat_vect)\n",
        "print(sent_topic[0])"
      ],
      "metadata": {
        "id": "L9MbFvkOeHg0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "doc_per_topic_list = []\n",
        "for n in range(sent_topic.shape[0]):\n",
        "    topic_most_pr = sent_topic[n].argmax()\n",
        "    topic_pr = sent_topic[n].max()\n",
        "    doc_per_topic_list.append([n,topic_most_pr,topic_pr])\n",
        "\n",
        "doc_topic_df = pd.DataFrame(doc_per_topic_list,columns=['no','토픽번호','확률'])\n",
        "doc_topic_df\n",
        "\n"
      ],
      "metadata": {
        "id": "GTa1Jzt8hQAE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for topic in range(len(doc_topic_df['토픽번호'].unique())):\n",
        "    print('토픽',topic)\n",
        "    top_topic = doc_topic_df[ doc_topic_df['토픽번호']==topic].sort_values(by='확률',ascending=False)\n",
        "    print(df['text'].iloc[ top_topic['no'].iloc[0]])\n",
        "    print(df['text'].iloc[ top_topic['no'].iloc[1]])\n",
        "    print(df['text'].iloc[ top_topic['no'].iloc[2]])"
      ],
      "metadata": {
        "id": "I8p6GKKIiKRk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 분석 결과"
      ],
      "metadata": {
        "id": "7G-AhkSoE4l7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**0**  \n",
        "상품, 매장, 가입, 주문, 검색, 물건, 회원, 선택, 품절, 어플, 회원가입, 제품, 해도, 안됨, 취소, 하면, 결제, 해야, 삭제, 구매, 장바구니, 다이소, 해서, 없는, 하는, 옵션, 있는, 사항, 사용\n",
        "\n",
        "**1**  \n",
        "매장, 검색, 재고, 주소, 등록, 다이소, 배송지, 안됨, 입력, 지역, 없다고, 근처, 확인, 온라인, 서비스, 가능한, 매장 검색, 매장 재고, 배송지 입력, 되는, 없네요, 하나, 안되고, 배달, 배송지 등록, 안도는, 건지, 진짜, 상품\n",
        "\n",
        "**2**  \n",
        "다이소, 지역, 배달, 불가, 배송비, 가능, 고객, 제품, 물건, 불가 지역, 있는, 하는데, 설정, 상품, 주문, 이용, 있어서, 좋아요, 무슨, 저희, 구매, 다른, 해도, 경우, 어플, 서비스, 갑자기, 택배, 합니다, 배송 불가\n",
        "\n",
        "**3**  \n",
        "매장, 다이소, 지역, 픽업, 로그인, 아이디, 서비스, 실행, 사용, 어플, 다시, 진짜, 주변, 개선, 안됨, 이용, 안되는, 있는데, 계속, 군데, 오류, 하면, 그냥, 근처, 좋겠어요, 안되네요, 입력, 서비스 지역, 접속, 문의\n",
        "\n",
        "**4**   \n",
        "로그인, 지역, 어플, 오류, 연결, 인터넷, 계속, 화면, 인터넷 연결, 온라인, 사용, 서비스, 가능 지역, 하면, 설정, 가능, 가입, 안되고, 주소, 하지, 하는, 접속, 와이파이, 했는데, 회원 가입, 데이터, 문제, 최악, 해주세요, 제대로\n",
        "\n",
        "-> 정확하지 않은 매장 결과과"
      ],
      "metadata": {
        "id": "NuFN6YZt_Epw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **결론**"
      ],
      "metadata": {
        "id": "6cnwJ69JFQga"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "토픽 1,2,3,4,5에서 공통적으로 '안됨, 없네요, 안되고, 안되는, 불가, 배송 불가, 오류, 안되네요'와 같은 부정적인 키워드들을 볼 수 있으며, 이를 통해 앱에서 이용하고자하는 서비스가 제대로 되지 않는다는 것을 볼 수 있다.\n",
        "\n",
        "1. 특정 지역 배송 안됨 : 토픽0, 토픽1, 토픽2, 토픽4\n",
        "2. 어플 연결 오류: 토픽0, 토픽1, 토픽2, 토픽3, \n",
        "3. 특정 지역 매장에서 사용 불가 : 토픽0, 토픽2,  토픽4\n",
        "4. 앱 서비스가 제대로 제공되지 않음\n",
        "- 재고파악이 제대로 되지 않음 - 토픽4\n",
        "- 픽업 주문이 제대로 실행되지 않음 - 토픽4\n",
        "- 앱에서 주문 취소가 이루어지지 않음 - 토픽3\n",
        "\n"
      ],
      "metadata": {
        "id": "l9mlq2hwHyh_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "앱 개선 사항\n",
        "\n",
        "- 재고 : 재고가 어느 정도 남았는지, 품절상태인지, 입고예정이 있는지 없는지\n",
        "\n",
        "- 배송 : 배송지 확대, 옵션 선택\n",
        "\n",
        "- 픽업 : 픽업이 원활히 진행될 수 있도록 각 매장별 관리 시스템 도입, 매장 픽업비(종이백 필수에서 그냥 들고가거나, 장바구니 사용)\n",
        "\n",
        "- 특정 매장 픽업 서비스 불가 : 물류 센터에서 각 매장별 들어온 주문 상품을 전달함으로써.."
      ],
      "metadata": {
        "id": "EKPxG4MSNUES"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "d-Pdu216PLqI"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}